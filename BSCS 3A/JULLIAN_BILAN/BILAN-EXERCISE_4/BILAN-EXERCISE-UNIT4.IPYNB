{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "988f8d4d",
   "metadata": {},
   "source": [
    "# Exercise for Unit 4.1 — Naïve Bayes\n",
    "\n",
    "**Name:** Jullian Bilan, Kyla Elijah Ramiro \n",
    "\n",
    "**Date:** February 12, 2026  \n",
    "\n",
    "**Year and Section:** BSCS 3A"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80ec5250",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1 — Manual Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "768e2f3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BAG OF WORDS (Word Frequency):\n",
      "==================================================\n",
      "\n",
      "SPAM:\n",
      "{'free': 2, 'money': 1, 'now': 1, 'lowest': 1, 'price': 1, 'for': 2, 'your': 1, 'meds': 1, 'win': 1, 'a': 1, 'iphone': 1, 'today': 1, 'get': 1, '50': 1, 'off': 1, 'limited': 1, 'time': 1, 'click': 1, 'here': 1, 'prizes': 1}\n",
      "\n",
      "HAM:\n",
      "{'hi': 1, 'mom': 1, 'how': 1, 'are': 2, 'you': 2, 'we': 1, 'still': 1, 'on': 1, 'for': 1, 'dinner': 1, 'lets': 1, 'catch': 1, 'up': 1, 'tomorrow': 2, 'at': 2, 'the': 3, 'office': 2, 'meeting': 2, '3': 1, 'pm': 1, 'team': 1, 'in': 1, 'can': 1, 'send': 1, 'report': 1}\n"
     ]
    }
   ],
   "source": [
    "# Dataset\n",
    "documents = [\n",
    "    (\"Free money now!!!\", \"SPAM\"),\n",
    "    (\"Hi mom, how are you?\", \"HAM\"),\n",
    "    (\"Lowest price for your meds\", \"SPAM\"),\n",
    "    (\"Are we still on for dinner?\", \"HAM\"),\n",
    "    (\"Win a free iPhone today\", \"SPAM\"),\n",
    "    (\"Let's catch up tomorrow at the office\", \"HAM\"),\n",
    "    (\"Meeting at 3 PM tomorrow\", \"HAM\"),\n",
    "    (\"Get 50% off, limited time!\", \"SPAM\"),\n",
    "    (\"Team meeting in the office\", \"HAM\"),\n",
    "    (\"Click here for prizes!\", \"SPAM\"),\n",
    "    (\"Can you send the report?\", \"HAM\")\n",
    "]\n",
    "\n",
    "# a. Generate Bag of Words (word frequency)\n",
    "def bag_of_words(documents):\n",
    "    bow = {}\n",
    "    vocabulary = set()\n",
    "    \n",
    "    for doc, label in documents:\n",
    "        words = doc.lower().split()\n",
    "        \n",
    "        if label not in bow:\n",
    "            bow[label] = {}\n",
    "        \n",
    "        for word in words:\n",
    "            # Remove punctuation for word normalization\n",
    "            cleaned_word = ''.join(c for c in word if c.isalnum())\n",
    "            if cleaned_word:\n",
    "                vocabulary.add(cleaned_word)\n",
    "                if cleaned_word not in bow[label]:\n",
    "                    bow[label][cleaned_word] = 0\n",
    "                bow[label][cleaned_word] += 1\n",
    "    \n",
    "    return bow, vocabulary\n",
    "\n",
    "# Generate Bag of Words output\n",
    "bow, vocabulary = bag_of_words(documents)\n",
    "\n",
    "# Display results\n",
    "print(\"BAG OF WORDS (Word Frequency):\")\n",
    "print(\"=\" * 50)\n",
    "for label, words in bow.items():\n",
    "    print(f\"\\n{label}:\")\n",
    "    print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "3d8800b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PRIORS (P(Class)):\n",
      "==================================================\n",
      "P(SPAM) = 0.4545\n",
      "P(HAM) = 0.5455\n"
     ]
    }
   ],
   "source": [
    "# b. Calculate prior probability for each class\n",
    "def calculate_priors(documents):\n",
    "    class_counts = {}\n",
    "    total_docs = len(documents)\n",
    "    \n",
    "    for doc, label in documents:\n",
    "        if label not in class_counts:\n",
    "            class_counts[label] = 0\n",
    "        class_counts[label] += 1\n",
    "    \n",
    "    priors = {}\n",
    "    for label, count in class_counts.items():\n",
    "        priors[label] = count / total_docs\n",
    "    \n",
    "    return priors\n",
    "\n",
    "# Generate priors\n",
    "priors = calculate_priors(documents)\n",
    "\n",
    "# Display results\n",
    "print(\"PRIORS (P(Class)):\")\n",
    "print(\"=\" * 50)\n",
    "for label, prior in priors.items():\n",
    "    print(f\"P({label}) = {prior:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bb8577eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LIKELIHOOD (P(Word|Class)):\n",
      "==================================================\n",
      "\n",
      "SPAM:\n",
      "  P(3|SPAM) = 0.015152\n",
      "  P(50|SPAM) = 0.030303\n",
      "  P(a|SPAM) = 0.030303\n",
      "  P(are|SPAM) = 0.015152\n",
      "  P(at|SPAM) = 0.015152\n",
      "  P(can|SPAM) = 0.015152\n",
      "  P(catch|SPAM) = 0.015152\n",
      "  P(click|SPAM) = 0.030303\n",
      "  P(dinner|SPAM) = 0.015152\n",
      "  P(for|SPAM) = 0.045455\n",
      "  P(free|SPAM) = 0.045455\n",
      "  P(get|SPAM) = 0.030303\n",
      "  P(here|SPAM) = 0.030303\n",
      "  P(hi|SPAM) = 0.015152\n",
      "  P(how|SPAM) = 0.015152\n",
      "  P(in|SPAM) = 0.015152\n",
      "  P(iphone|SPAM) = 0.030303\n",
      "  P(lets|SPAM) = 0.015152\n",
      "  P(limited|SPAM) = 0.030303\n",
      "  P(lowest|SPAM) = 0.030303\n",
      "  P(meds|SPAM) = 0.030303\n",
      "  P(meeting|SPAM) = 0.015152\n",
      "  P(mom|SPAM) = 0.015152\n",
      "  P(money|SPAM) = 0.030303\n",
      "  P(now|SPAM) = 0.030303\n",
      "  P(off|SPAM) = 0.030303\n",
      "  P(office|SPAM) = 0.015152\n",
      "  P(on|SPAM) = 0.015152\n",
      "  P(pm|SPAM) = 0.015152\n",
      "  P(price|SPAM) = 0.030303\n",
      "  P(prizes|SPAM) = 0.030303\n",
      "  P(report|SPAM) = 0.015152\n",
      "  P(send|SPAM) = 0.015152\n",
      "  P(still|SPAM) = 0.015152\n",
      "  P(team|SPAM) = 0.015152\n",
      "  P(the|SPAM) = 0.015152\n",
      "  P(time|SPAM) = 0.030303\n",
      "  P(today|SPAM) = 0.030303\n",
      "  P(tomorrow|SPAM) = 0.015152\n",
      "  P(up|SPAM) = 0.015152\n",
      "  P(we|SPAM) = 0.015152\n",
      "  P(win|SPAM) = 0.030303\n",
      "  P(you|SPAM) = 0.015152\n",
      "  P(your|SPAM) = 0.030303\n",
      "\n",
      "HAM:\n",
      "  P(3|HAM) = 0.025974\n",
      "  P(50|HAM) = 0.012987\n",
      "  P(a|HAM) = 0.012987\n",
      "  P(are|HAM) = 0.038961\n",
      "  P(at|HAM) = 0.038961\n",
      "  P(can|HAM) = 0.025974\n",
      "  P(catch|HAM) = 0.025974\n",
      "  P(click|HAM) = 0.012987\n",
      "  P(dinner|HAM) = 0.025974\n",
      "  P(for|HAM) = 0.025974\n",
      "  P(free|HAM) = 0.012987\n",
      "  P(get|HAM) = 0.012987\n",
      "  P(here|HAM) = 0.012987\n",
      "  P(hi|HAM) = 0.025974\n",
      "  P(how|HAM) = 0.025974\n",
      "  P(in|HAM) = 0.025974\n",
      "  P(iphone|HAM) = 0.012987\n",
      "  P(lets|HAM) = 0.025974\n",
      "  P(limited|HAM) = 0.012987\n",
      "  P(lowest|HAM) = 0.012987\n",
      "  P(meds|HAM) = 0.012987\n",
      "  P(meeting|HAM) = 0.038961\n",
      "  P(mom|HAM) = 0.025974\n",
      "  P(money|HAM) = 0.012987\n",
      "  P(now|HAM) = 0.012987\n",
      "  P(off|HAM) = 0.012987\n",
      "  P(office|HAM) = 0.038961\n",
      "  P(on|HAM) = 0.025974\n",
      "  P(pm|HAM) = 0.025974\n",
      "  P(price|HAM) = 0.012987\n",
      "  P(prizes|HAM) = 0.012987\n",
      "  P(report|HAM) = 0.025974\n",
      "  P(send|HAM) = 0.025974\n",
      "  P(still|HAM) = 0.025974\n",
      "  P(team|HAM) = 0.025974\n",
      "  P(the|HAM) = 0.051948\n",
      "  P(time|HAM) = 0.012987\n",
      "  P(today|HAM) = 0.012987\n",
      "  P(tomorrow|HAM) = 0.038961\n",
      "  P(up|HAM) = 0.025974\n",
      "  P(we|HAM) = 0.025974\n",
      "  P(win|HAM) = 0.012987\n",
      "  P(you|HAM) = 0.038961\n",
      "  P(your|HAM) = 0.012987\n"
     ]
    }
   ],
   "source": [
    "# c. Calculate likelihood of tokens with respect to class\n",
    "def calculate_likelihoods(documents):\n",
    "    bow, vocabulary = bag_of_words(documents)\n",
    "    likelihoods = {}\n",
    "    \n",
    "    for label in bow:\n",
    "        likelihoods[label] = {}\n",
    "        total_words_in_class = sum(bow[label].values())\n",
    "        vocab_size = len(vocabulary)\n",
    "        \n",
    "        for word in vocabulary:\n",
    "            word_count = bow[label].get(word, 0)\n",
    "            # Using Laplace smoothing to avoid zero probability\n",
    "            likelihood = (word_count + 1) / (total_words_in_class + vocab_size)\n",
    "            likelihoods[label][word] = likelihood\n",
    "    \n",
    "    return likelihoods, vocabulary\n",
    "\n",
    "# Generate likelihoods\n",
    "likelihoods, vocabulary = calculate_likelihoods(documents)\n",
    "\n",
    "# Display results\n",
    "print(\"LIKELIHOOD (P(Word|Class)):\")\n",
    "print(\"=\" * 50)\n",
    "for label, words_likelihood in likelihoods.items():\n",
    "    print(f\"\\n{label}:\")\n",
    "    for word, likelihood in sorted(words_likelihood.items()):\n",
    "        print(f\"  P({word}|{label}) = {likelihood:.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c526842a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# d. Determine class for test sentences\n",
    "\n",
    "# Prediction function\n",
    "def predict_class(test_doc, priors, likelihoods, vocabulary):\n",
    "    scores = {}\n",
    "    \n",
    "    # Clean and tokenize test document\n",
    "    words = test_doc.lower().split()\n",
    "    cleaned_words = set(''.join(c for c in word if c.isalnum()) for word in words)\n",
    "    cleaned_words = {w for w in cleaned_words if w}\n",
    "    \n",
    "    for label in priors:\n",
    "        # Start with prior probability\n",
    "        score = priors[label]\n",
    "        \n",
    "        # Multiply by likelihood of each word\n",
    "        for word in cleaned_words:\n",
    "            if word in likelihoods[label]:\n",
    "                score *= likelihoods[label][word]\n",
    "        \n",
    "        scores[label] = score\n",
    "    \n",
    "    # Return class with highest score\n",
    "    predicted_class = max(scores, key=scores.get)\n",
    "    return predicted_class, scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "aed10e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentence i: 'Limited offer, click here!'\n",
      "==================================================\n",
      "Predicted Class: SPAM\n",
      "Scores: {'SPAM': 1.2648397321575385e-05, 'HAM': 1.1947757236706776e-06}\n",
      "HAM Score: 0.0000011948\n",
      "SPAM Score: 0.0000126484\n"
     ]
    }
   ],
   "source": [
    "# i. Test sentence: Limited offer, click here!\n",
    "test_doc_i = \"Limited offer, click here!\"\n",
    "predicted_class_i, scores_i = predict_class(test_doc_i, priors, likelihoods, vocabulary)\n",
    "\n",
    "print(\"Test Sentence i: 'Limited offer, click here!'\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Predicted Class: {predicted_class_i}\")\n",
    "print(f\"Scores: {scores_i}\")\n",
    "print(f\"HAM Score: {scores_i['HAM']:.10f}\")\n",
    "print(f\"SPAM Score: {scores_i['SPAM']:.10f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "273163b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Sentence ii: 'Meeting at 2 PM with the manager.'\n",
      "==================================================\n",
      "Predicted Class: HAM\n",
      "Scores: {'SPAM': 2.395529795752914e-08, 'HAM': 1.1171928844712829e-06}\n",
      "HAM Score: 0.0000011172\n",
      "SPAM Score: 0.0000000240\n"
     ]
    }
   ],
   "source": [
    "# ii. Test sentence: Meeting at 2 PM with the manager.\n",
    "test_doc_ii = \"Meeting at 2 PM with the manager.\"\n",
    "predicted_class_ii, scores_ii = predict_class(test_doc_ii, priors, likelihoods, vocabulary)\n",
    "\n",
    "print(\"Test Sentence ii: 'Meeting at 2 PM with the manager.'\")\n",
    "print(\"=\" * 50)\n",
    "print(f\"Predicted Class: {predicted_class_ii}\")\n",
    "print(f\"Scores: {scores_ii}\")\n",
    "print(f\"HAM Score: {scores_ii['HAM']:.10f}\")\n",
    "print(f\"SPAM Score: {scores_ii['SPAM']:.10f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33e5e23c",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2 — Naïve Bayes Using Scikit-Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "5afab1da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully.\n",
      "Classes: ['HAM' 'SPAM']\n",
      "Feature names (42): ['50', 'are', 'at', 'can', 'catch', 'click', 'dinner', 'for', 'free', 'get', 'here', 'hi', 'how', 'in', 'iphone', 'let', 'limited', 'lowest', 'meds', 'meeting', 'mom', 'money', 'now', 'off', 'office', 'on', 'pm', 'price', 'prizes', 'report', 'send', 'still', 'team', 'the', 'time', 'today', 'tomorrow', 'up', 'we', 'win', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "# Prepare training data\n",
    "train_texts = [text for text, _ in documents]\n",
    "train_labels = [label for _, label in documents]\n",
    "\n",
    "# Vectorize (Bag of Words)\n",
    "vectorizer = CountVectorizer()\n",
    "X_train = vectorizer.fit_transform(train_texts)\n",
    "\n",
    "# Train Multinomial Naïve Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, train_labels)\n",
    "\n",
    "print(\"Model trained successfully.\")\n",
    "print(f\"Classes: {model.classes_}\")\n",
    "print(f\"Feature names ({len(vectorizer.get_feature_names_out())}): \"\n",
    "      f\"{list(vectorizer.get_feature_names_out())}\")\n",
    "\n",
    "test_sentences = [\n",
    "    \"Limited offer, click here!\",\n",
    "    \"Meeting at 2 PM with the manager.\",\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a93aa36c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model trained successfully.\n",
      "Classes: ['HAM' 'SPAM']\n",
      "Feature names (42): ['50', 'are', 'at', 'can', 'catch', 'click', 'dinner', 'for', 'free', 'get', 'here', 'hi', 'how', 'in', 'iphone', 'let', 'limited', 'lowest', 'meds', 'meeting', 'mom', 'money', 'now', 'off', 'office', 'on', 'pm', 'price', 'prizes', 'report', 'send', 'still', 'team', 'the', 'time', 'today', 'tomorrow', 'up', 'we', 'win', 'you', 'your']\n"
     ]
    }
   ],
   "source": [
    "# Train Multinomial Naïve Bayes\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, train_labels)\n",
    "\n",
    "print(\"Model trained successfully.\")\n",
    "print(f\"Classes: {model.classes_}\")\n",
    "print(f\"Feature names ({len(vectorizer.get_feature_names_out())}): \"\n",
    "      f\"{list(vectorizer.get_feature_names_out())}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f3f0a6f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Scikit-Learn Multinomial NB — Classification Results\n",
      "============================================================\n",
      "\n",
      "Sentence : \"Limited offer, click here!\"\n",
      "  P(HAM | doc) = 0.0847\n",
      "  P(SPAM | doc) = 0.9153\n",
      "  ➜ Predicted class: SPAM\n",
      "\n",
      "Sentence : \"Meeting at 2 PM with the manager.\"\n",
      "  P(HAM | doc) = 0.9784\n",
      "  P(SPAM | doc) = 0.0216\n",
      "  ➜ Predicted class: HAM\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Classify the test sentences\n",
    "X_test = vectorizer.transform(test_sentences)\n",
    "predictions = model.predict(X_test)\n",
    "probabilities = model.predict_proba(X_test)\n",
    "\n",
    "print(\"=\" * 60)\n",
    "print(\"Scikit-Learn Multinomial NB — Classification Results\")\n",
    "print(\"=\" * 60)\n",
    "\n",
    "for sentence, pred, probs in zip(test_sentences, predictions, probabilities):\n",
    "    print(f\"\\nSentence : \\\"{sentence}\\\"\")\n",
    "    for cls, prob in zip(model.classes_, probs):\n",
    "        print(f\"  P({cls} | doc) = {prob:.4f}\")\n",
    "    print(f\"  ➜ Predicted class: {pred}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
